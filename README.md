# ğŸ¤– Limo Soccer RL

Projet de recherche et dâ€™expÃ©rimentation en **apprentissage par renforcement (Reinforcement Learning)** appliquÃ© Ã  des robots mobiles de type LIMO Ã©voluant dans un environnement de football robotique.

Lâ€™objectif est de construire une pipeline **progressive** allant dâ€™un agent seul jusquâ€™Ã  un **duel compÃ©titif**, en Ã©tudiant la stabilitÃ© de lâ€™apprentissage, la gÃ©nÃ©ralisation et les performances des politiques PPO.

---

## ğŸ¯ Objectifs du projet

- Concevoir un **environnement Gymnasium** personnalisÃ© pour le football robotique
- EntraÃ®ner un agent via **PPO (Stable-Baselines3)**
- Apprendre la navigation et le contrÃ´le du ballon de maniÃ¨re robuste  
- GÃ©rer des comportements adverses  
- Comparer les approches classiques et hiÃ©rarchiques d'apprentissage par renforcement
- Comparer les performances des modÃ¨les (winrate, buts marquÃ©s/encaissÃ©s)

Ce projet sâ€™inscrit dans un cadre acadÃ©mique (Projet 5A) et vise une qualitÃ© reproductible et analysable.

---

## ğŸ§© Pipeline expÃ©rimentale

Le projet est entiÃ¨rement versionnÃ© via des branches Git :

### Ã‰tapes principales (validÃ©es)

- **Ã‰tape 1 â€” But cage (basÃ© sur Lidar)**  
  - Position initiale du robot fixe  
  - Ballon au centre  
  - Observations basÃ©es uniquement sur le Lidar  

- **Ã‰tape 2 â€” RL classique**  
  - Positions alÃ©atoires du robot et du ballon  
  - PPO avec Î³ = 0,99  

- **Ã‰tape 3 â€” Adversaire statique**  
  - Adversaire figÃ©  
  - RÃ©compense explicite pour Ã©viter les collisions  

- **Ã‰tape 4 â€” Duel**  
  - Deux agents, buts indÃ©pendants  
  - Apprentissage par renforcement compÃ©titif

### ExpÃ©rimentations (abandonnÃ©es ou exploratoires)

- Apprentissage par renforcement hiÃ©rarchique  
- PPO avec Î³ = 0,995  
- Adversaire statique sans pÃ©nalitÃ© de collision

---

## ğŸ“ Structure du dÃ©pÃ´t

- `main` â†’ ImplÃ©mentation finale du duel
```
limo-soccer-rl/
â”‚
â”œâ”€â”€ envs/
â”‚ â”œâ”€â”€ limo_soccer_env.py # Environnement solo
â”‚ â”œâ”€â”€ limo_soccer_env_static.py # Adversaire statique
â”‚ â””â”€â”€ limo_soccer_env_duel.py # Duel 1v1
â”‚
â”œâ”€â”€ train/
â”‚ â”œâ”€â”€ train_solo.py
â”‚ â”œâ”€â”€ train_static.py
â”‚ â””â”€â”€ train_duel.py
â”‚
â”œâ”€â”€ eval/
â”‚ â”œâ”€â”€ eval_model.py
â”‚ â”œâ”€â”€ test_vs_models_duel.py
â”‚ â””â”€â”€ analyze_results.py
â”‚
â”œâ”€â”€ models/ # ModÃ¨les entraÃ®nÃ©s (ignorÃ© par git)
â”œâ”€â”€ logs/ # TensorBoard logs (ignorÃ© par git)
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```
- `dev` â†’ Branche d'intÃ©gration  
- `stage/*` â†’ Jalons de dÃ©veloppement validÃ©s  
- `experiment/*` â†’ Approches exploratoires ou abandonnÃ©es

---

## Outils & bibliothÃ¨ques

- Python  
- Stable-Baselines3 (PPO)  
- Gymnasium  
- NumPy  
- PyGame (affichage)  
- TensorBoard (analyse de l'entraÃ®nement)

---

## âš™ï¸Installation

### 1. Cloner le dÃ©pÃ´t

```
git clone https://github.com/Paul-Faroult/limo-soccer-rl.git
cd limo-soccer-rl
```

### CrÃ©er un environnement virtuel

```
python -m venv venv
source venv/bin/activate # Linux / Mac
venv\Scripts\activate # Windows
```

### Installer les dÃ©pendances

```
pip install -r requirements.txt
```

---

## ğŸš€ EntraÃ®nement

### Agent solo

## RÃ©sultats

L'agent final montre :  

- Interception du ballon robuste  
- Ã‰vitement adaptatif de lâ€™adversaire  
- Comportement de marquage de but compÃ©titif

---

## Auteurs

- Paul Faroult  
- Ba Thong Nguyen  

Projet acadÃ©mique dÃ©veloppÃ© dans le cadre d'expÃ©rimentations en apprentissage par renforcement.
